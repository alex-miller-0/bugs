{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Severity Using NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import sklearn.metrics\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore') #do not display warnings (SettingWithCopyWarning etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/df_nlp_severity.pkl')\n",
    "#word_list_reduced = pickle.load(open('../data/vocabulary.pkl', 'rb'))\n",
    "vectorizer = pickle.load(open('../data/tfidf_vectorizer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only look at not normal (default)\n",
    "\n",
    "*\"Following the work of Lamkanfi et al. [15, 16], we do not consider the severity label normal as this is the default option and “many reports just did not bother to consciously assess the bug severity” [15, 16]. Thus we treat this data as unlabeled data and do not use it for our testing.\" Information Retrieval Based Nearest Neighbor Classification for Fine-Grained Bug Severity Prediction: Tian, Lo, Sun, 2011*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_fixed = df[df['severity_final'] != 'enhancement']\n",
    "df_fixed = df_fixed[df_fixed['severity_final'] != 'normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "critical    35149\n",
       "major       35078\n",
       "minor       17830\n",
       "trivial      7429\n",
       "blocker      3740\n",
       "Name: severity_final, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fixed['severity_final'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all = df_fixed['desc_init']\n",
    "#X_all = df['short_desc_init']\n",
    "y_all = df_fixed['severity_final']\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X_all, y_all, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority is 35.4546553971% cases in train\n",
      "Majority is 35.340831217% cases in test\n"
     ]
    }
   ],
   "source": [
    "print 'Majority is {}% cases in train'.format(y.value_counts().max() * 100 / y.value_counts().sum())\n",
    "print 'Majority is {}% cases in test'.format(y_test.value_counts().max() * 100 / y_test.value_counts().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74419, 20000)\n",
      "(24807, 20000)\n"
     ]
    }
   ],
   "source": [
    "tfidf = vectorizer.transform(X)\n",
    "print tfidf.shape\n",
    "tfidf_test = vectorizer.transform(X_test)\n",
    "print tfidf_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB - desc_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.fit(tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.540855403717\n",
      "precision: 0.564328830269\n",
      "recall: 0.540855403717\n",
      "\n",
      "confusion matrix: \n",
      " [[  82  298  501   43    7]\n",
      " [  95 4819 3670  169   11]\n",
      " [ 113  820 7113  706   15]\n",
      " [  28  292 2848 1324   48]\n",
      " [  10  181 1002  533   79]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = nb_model.predict(tfidf_test)\n",
    "\n",
    "print 'accuracy: {}'.format(sklearn.metrics.accuracy_score(y_test, y_pred))\n",
    "print 'precision: {}'.format(sklearn.metrics.precision_score(y_test, y_pred))\n",
    "print 'recall: {}'.format(sklearn.metrics.recall_score(y_test, y_pred))\n",
    "print ''\n",
    "print 'confusion matrix: \\n {}'.format(sklearn.metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results to beat:**\n",
    "```\n",
    "Severity  Precision  Recall  F-Measure\n",
    "blocker   53.4%       8.0%   13.9%\n",
    "critical  69.6%      61.6%   65.3%\n",
    "major     52.0%      60.2%   55.8%\n",
    "minor     42.0%      15.7%   22.9%\n",
    "trivial   60.5%      12.4%   20.6%\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    blocker       0.25      0.09      0.13       931\n",
      "   critical       0.75      0.55      0.64      8764\n",
      "      major       0.47      0.81      0.60      8767\n",
      "      minor       0.48      0.29      0.36      4540\n",
      "    trivial       0.49      0.04      0.08      1805\n",
      "\n",
      "avg / total       0.56      0.54      0.51     24807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'classification report: \\n {}'.format(sklearn.metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest - desc_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=20, criterion='gini', \n",
    "                               max_depth=3, max_features='auto', \n",
    "                               bootstrap=True, oob_score=True,\n",
    "                               random_state=None, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.fit(tfidf,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature importances: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "oob score: 0.449858235128\n",
      "\n",
      "accuracy: 0.459789575523\n",
      "precision: 0.325742214826\n",
      "recall: 0.459789575523\n",
      "\n",
      "confusion matrix: \n",
      " [[   0  728  203    0    0]\n",
      " [   0 5586 3178    0    0]\n",
      " [   0 2947 5820    0    0]\n",
      " [   0 1617 2923    0    0]\n",
      " [   0  766 1039    0    0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_model.predict(tfidf_test)\n",
    "\n",
    "print 'feature importances: {}'.format(rf_model.feature_importances_)\n",
    "print 'oob score: {}'.format(rf_model.oob_score_)\n",
    "print ''\n",
    "print 'accuracy: {}'.format(sklearn.metrics.accuracy_score(y_test, y_pred))\n",
    "print 'precision: {}'.format(sklearn.metrics.precision_score(y_test, y_pred))\n",
    "print 'recall: {}'.format(sklearn.metrics.recall_score(y_test, y_pred))\n",
    "print ''\n",
    "print 'confusion matrix: \\n {}'.format(sklearn.metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost - desc_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_model = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, \n",
    "                                   n_estimators=100, subsample=1.0,\n",
    "                                   max_depth=3, init=None, \n",
    "                                   random_state=None, max_features=None, \n",
    "                                   verbose=0, max_leaf_nodes=None, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_model.fit(tfidf,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature importances: [ 0.          0.00066981  0.         ...,  0.          0.          0.        ]\n",
      "\n",
      "accuracy: 0.298146853147\n",
      "precision: 0.279535725834\n",
      "recall: 0.298146853147\n",
      "\n",
      "confusion matrix: \n",
      " [[4915   96  273  495  912]\n",
      " [3331  120  276  549  816]\n",
      " [3228  107  331  686 1173]\n",
      " [2827   86  315  872 1503]\n",
      " [2391   57  200  752 2289]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = gb_model.predict(tfidf_test.toarray())\n",
    "\n",
    "print 'feature importances: {}'.format(gb_model.feature_importances_)\n",
    "print ''\n",
    "print 'accuracy: {}'.format(sklearn.metrics.accuracy_score(y_test, y_pred))\n",
    "print 'precision: {}'.format(sklearn.metrics.precision_score(y_test, y_pred))\n",
    "print 'recall: {}'.format(sklearn.metrics.recall_score(y_test, y_pred))\n",
    "print ''\n",
    "print 'confusion matrix: \\n {}'.format(sklearn.metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
