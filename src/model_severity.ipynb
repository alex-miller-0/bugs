{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pymongo\n",
    "import json\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import sklearn.metrics\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://lucka@localhost:5432/bugs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql_query('select * from final',con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get rid of enhancements\n",
    "df = df[df['severity_init'] != 'enhancement']\n",
    "\n",
    "# calc resolution time (duration)\n",
    "df['duration'] = df['closing'] - df['opening']\n",
    "df['duration_days'] = df['duration'].apply(lambda x: float(x.days))\n",
    "\n",
    "# is there assignee\n",
    "df['assigned_to_init_bool'] = df['assigned_to_init'].map(lambda x: 0 if x == '' else 1)\n",
    "\n",
    "# bug_status to int\n",
    "bug_status_map = dict({'new':1, 'unconfirmed':2, 'assigned':3, 'resolved':4, 'verified':5, 'closed':6, 'reopened':7})\n",
    "df['bug_status_init'] = df['bug_status_init'].map(lambda x: bug_status_map[x] if x in bug_status_map.keys() else 0)\n",
    "df['bug_status_final'] = df['bug_status_final'].map(lambda x: bug_status_map[x] if x in bug_status_map.keys() else 0)\n",
    "\n",
    "# count number of initially cced\n",
    "df['cc_init_cnt'] = df['cc_init'].map(lambda x: x.count('@'))\n",
    "\n",
    "# priority to int\n",
    "priority_map = dict({'p1':1, 'p2':2, 'p3':3, 'p4':4, 'p5':5})\n",
    "df['priority_init'] = df['priority_init'].map(lambda x: priority_map[x] if x in priority_map.keys() else 0)\n",
    "df['priority_final'] = df['priority_final'].map(lambda x: priority_map[x] if x in priority_map.keys() else 0)\n",
    "\n",
    "# only keep top products\n",
    "product_map = dict({'core':1, 'firefox':2, 'thunderbird':3, 'bugzilla':4, 'browser':5, 'webtools':6, 'psm':7})\n",
    "df['top_product_init'] = df['product_init'].map(lambda x: product_map[x] if x in product_map.keys() else 0)\n",
    "df['top_product_final'] = df['product_final'].map(lambda x: product_map[x] if x in product_map.keys() else 0)\n",
    "\n",
    "# severity to int\n",
    "severity_map = dict({'trivial':1, 'minor':2, 'normal':3, 'major':4, 'critical':5, 'blocker':6})\n",
    "df['severity_init'] = df['severity_init'].map(lambda x: severity_map[x] if x in severity_map.keys() else 0)\n",
    "df['severity_final'] = df['severity_final'].map(lambda x: severity_map[x] if x in severity_map.keys() else 0)\n",
    "\n",
    "# version to int\n",
    "version_map = dict({'trunk':1, 'unspecified':2, 'other':3, 'other branch':4, '2.0 branch':5, '1.0 branch':6})\n",
    "df['version_init'] = df['version_init'].map(lambda x: version_map[x] if x in version_map.keys() else 0)\n",
    "df['version_final'] = df['version_final'].map(lambda x: version_map[x] if x in version_map.keys() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# short_desc_init_wordcnt\n",
    "df['short_desc_init_wordcnt'] = df['short_desc_init'].map(lambda x: len(x.split()))\n",
    "\n",
    "# desc_wordcnt\n",
    "df['desc_init_wordcnt'] = df['desc_init'].map(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_init = df[[\n",
    "    #'reporter', #not really useful, is it?\n",
    "    'assigned_to_init_bool',\n",
    "    'bug_status_init',\n",
    "    'cc_init_cnt',\n",
    "    #'component_init', #need to vectorize\n",
    "    #'op_sys_init', #need to vetorize\n",
    "    #'priority_init', #almost always empty\n",
    "    'top_product_init',\n",
    "    #'severity_init',\n",
    "    'short_desc_init_wordcnt',\n",
    "    #'short_desc_init', #need to vectorize\n",
    "    'version_init',\n",
    "    #'desc_init',\n",
    "    'desc_init_wordcnt',\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>assigned_to_init_bool</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bug_status_init</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc_init_cnt</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_product_init</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_desc_init_wordcnt</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>version_init</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc_init_wordcnt</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0\n",
       "assigned_to_init_bool    0\n",
       "bug_status_init          1\n",
       "cc_init_cnt              0\n",
       "top_product_init         1\n",
       "short_desc_init_wordcnt  3\n",
       "version_init             1\n",
       "desc_init_wordcnt        0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_init.head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_all = df_init.values\n",
    "y_all = df['severity_final'].values\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X_all, y_all, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=20, criterion='gini', \n",
    "                               max_depth=3, max_features='auto', \n",
    "                               bootstrap=True, oob_score=True,\n",
    "                               random_state=None, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature importances: [  2.12418238e-03   3.90746602e-02   1.75534628e-03   3.24667723e-02\n",
      "   8.25498661e-01   4.73162562e-04   2.29645755e-02   7.56426401e-02]\n",
      "oob score: 0.825847948201\n",
      "\n",
      "accuracy: 0.842957664947\n",
      "precision: 0.756063791704\n",
      "recall: 0.842957664947\n",
      "\n",
      "confusion matrix: \n",
      " [[    0     0     0   835    55    24     0]\n",
      " [    0     0     0  1756    43    22     0]\n",
      " [    0     0     0  4320    66    22     0]\n",
      " [    0     0     0 51483   334   299     0]\n",
      " [    0     0     0  1120  7328   301     0]\n",
      " [    0     0     0  1727   335  6718     0]\n",
      " [    0     0     0   205    46   698     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucka/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lucka/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "print 'feature importances: {}'.format(rf_model.feature_importances_)\n",
    "print 'oob score: {}'.format(rf_model.oob_score_)\n",
    "print ''\n",
    "print 'accuracy: {}'.format(sklearn.metrics.accuracy_score(y_test, y_pred))\n",
    "print 'precision: {}'.format(sklearn.metrics.precision_score(y_test, y_pred))\n",
    "print 'recall: {}'.format(sklearn.metrics.recall_score(y_test, y_pred))\n",
    "print ''\n",
    "print 'confusion matrix: \\n {}'.format(sklearn.metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print y_pred.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_model = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, \n",
    "                                   n_estimators=100, subsample=1.0,\n",
    "                                   max_depth=3, init=None, \n",
    "                                   random_state=None, max_features=None, \n",
    "                                   verbose=0, max_leaf_nodes=None, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature importances: [ 0.03907605  0.13797198  0.0186802   0.24428588  0.14290109  0.12872565\n",
      "  0.28835914]\n",
      "\n",
      "accuracy: 0.670967492957\n",
      "precision: 0.582189220394\n",
      "recall: 0.670967492957\n",
      "\n",
      "confusion matrix: \n",
      " [[    0     1     0   911     0     0     2]\n",
      " [    1     3     0  1815     0     0     2]\n",
      " [    1     4     0  4398     0     5     0]\n",
      " [    0     7     0 51882     2   220     5]\n",
      " [    0     1     0  8704     3    40     1]\n",
      " [    2     0     0  8519     0   256     3]\n",
      " [    0     6     0   914     0    14    15]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucka/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lucka/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    }
   ],
   "source": [
    "y_pred = gb_model.predict(X_test)\n",
    "\n",
    "print 'feature importances: {}'.format(gb_model.feature_importances_)\n",
    "print ''\n",
    "print 'accuracy: {}'.format(sklearn.metrics.accuracy_score(y_test, y_pred))\n",
    "print 'precision: {}'.format(sklearn.metrics.precision_score(y_test, y_pred))\n",
    "print 'recall: {}'.format(sklearn.metrics.recall_score(y_test, y_pred))\n",
    "print ''\n",
    "print 'confusion matrix: \\n {}'.format(sklearn.metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP (TFIDF) on short_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with class imbalance (undersample normal (3) severity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102534\n",
      "137534\n"
     ]
    }
   ],
   "source": [
    "df_nlp = df[df['severity_final'] != 3][['short_desc_init','severity_final']]\n",
    "print len(df_nlp)\n",
    "df_nlp = df_nlp.append(df[df['severity_final'] == 3][['short_desc_init','severity_final']][:35000])\n",
    "print len(df_nlp)\n",
    "\n",
    "# shuffle by sampling the whole thing\n",
    "df_nlp = df_nlp.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    35128\n",
       "4    35034\n",
       "3    35000\n",
       "2    17764\n",
       "1     7397\n",
       "6     3728\n",
       "0     3483\n",
       "Name: severity_final, dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nlp['severity_final'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(df_nlp['short_desc_init'], df_nlp['severity_final'], test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversample normal (3) severity in test to make it more real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = X_test.append(df[df['severity_final'] == 3]['short_desc_init'][-10000:])\n",
    "y_test = y_test.append(df[df['severity_final'] == 3]['severity_final'][-10000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10033    unable to resolve url.\n",
      "Name: short_desc_init, dtype: object\n",
      "10033    3\n",
      "Name: severity_final, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print X_test.head(1)\n",
    "print y_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(input='content', lowercase=True, tokenizer=None, \n",
    "                        stop_words='english', use_idf=True)\n",
    "tfidf = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103150, 41279)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print tfidf.shape\n",
    "tfidf_test = vectorizer.transform(X_test)\n",
    "print tfidf_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.fit(tfidf,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.457091365624\n",
      "precision: 0.538161635446\n",
      "recall: 0.457091365624\n",
      "\n",
      "confusion matrix: \n",
      " [[    1     0    21   410   397    28     0]\n",
      " [    0    13    59  1040   662   121     1]\n",
      " [    0     3   110  1814  2304   253     0]\n",
      " [    0     2   217 10952 10169  2384     2]\n",
      " [    0     0    34  2026  5433  1248     0]\n",
      " [    0     0     8   778  1927  6019     0]\n",
      " [    0     0     8   248   403   244    45]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucka/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lucka/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    }
   ],
   "source": [
    "y_pred = nb_model.predict(tfidf_test)\n",
    "\n",
    "print 'accuracy: {}'.format(sklearn.metrics.accuracy_score(y_test, y_pred))\n",
    "print 'precision: {}'.format(sklearn.metrics.precision_score(y_test, y_pred))\n",
    "print 'recall: {}'.format(sklearn.metrics.recall_score(y_test, y_pred))\n",
    "print ''\n",
    "print 'confusion matrix: \\n {}'.format(sklearn.metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_model = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, \n",
    "                                   n_estimators=100, subsample=1.0,\n",
    "                                   max_depth=3, init=None, \n",
    "                                   random_state=None, max_features=None, \n",
    "                                   verbose=0, max_leaf_nodes=None, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runs about 5 mins for tfidf.shape (103150, 41279)\n",
    "gb_model.fit(tfidf,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature importances: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\n",
      "accuracy: 0.465798045603\n",
      "precision: 0.508639836125\n",
      "recall: 0.465798045603\n",
      "\n",
      "confusion matrix: \n",
      " [[  77    2   15  534  223    5    1]\n",
      " [   6   90   54 1314  410   20    2]\n",
      " [  10   45  222 2731 1377   92    7]\n",
      " [  38   42  110 5653 2372  489   22]\n",
      " [  19   12   76 4012 3922  688   12]\n",
      " [   6    3   13 1555 1193 5946   16]\n",
      " [   3    0    2  375  304  158  106]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucka/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lucka/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    }
   ],
   "source": [
    "y_pred = gb_model.predict(tfidf_test.toarray())\n",
    "\n",
    "print 'feature importances: {}'.format(gb_model.feature_importances_)\n",
    "print ''\n",
    "print 'accuracy: {}'.format(sklearn.metrics.accuracy_score(y_test, y_pred))\n",
    "print 'precision: {}'.format(sklearn.metrics.precision_score(y_test, y_pred))\n",
    "print 'recall: {}'.format(sklearn.metrics.recall_score(y_test, y_pred))\n",
    "print ''\n",
    "print 'confusion matrix: \\n {}'.format(sklearn.metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP (TFIDF) on description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_third = df[['desc_init', 'severity_final']].sample(frac=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118228    To reproduce:Type username and password and hi...\n",
       "123121    User-Agent:       Mozilla/5.0 (Windows; U; Win...\n",
       "62873     User-Agent:       Mozilla/5.0 (X11; U; Linux i...\n",
       "180568    User-Agent:       Mozilla/5.0 (X11; U; Linux i...\n",
       "268739    User-Agent:       Mozilla/4.0 (compatible; MSI...\n",
       "42303     User-Agent:       Mozilla/5.0 (X11; U; Linux i...\n",
       "236045    Using 3/19 build on Win 95, Win 98, Win NT, Ma...\n",
       "254036    User-Agent:       Mozilla/5.0 (Windows; U; Win...\n",
       "35525     Class CNewlineToken allocates an static variab...\n",
       "37281     Taken from bug 54194\\n\\nApplets do not print t...\n",
       "256194    Hovering over an active tab calls grab cursor ...\n",
       "102473    Build ID: 2005-06-09-06, Windows XP Seamonkey ...\n",
       "67634     User-Agent:       Mozilla/4.0 (compatible; MSI...\n",
       "320885    Using build 1999102008 on Win 95.\\n\\nOpen atta...\n",
       "163358    The |getElementByTagName| method of DOM |Docum...\n",
       "214512         port Altss fixes from Aviary Branch to Trunk\n",
       "11610     User-Agent:       Mozilla/5.0 (Windows; U; Win...\n",
       "92238     User-Agent:       Mozilla/5.0 (Windows; U; Win...\n",
       "132702                                                     \n",
       "173593    The ES6 String.prototype.reverse method return...\n",
       "283671    From Bugzilla Helper:\\nUser-Agent: Mozilla/5.0...\n",
       "143079    The problem here is that nsHTMLFrameOuterFrame...\n",
       "38893     The flags here are wrong (imgCache.cpp:102)\\n\\...\n",
       "268447    User-Agent:       Mozilla/4.0 (compatible; MSI...\n",
       "318557    When loading this page, the text in the right ...\n",
       "29853     User-Agent:       Mozilla/5.0 (Windows; U; Win...\n",
       "90854     Testcase attached.  The spec states very clear...\n",
       "204686    User-Agent:       Mozilla/5.0 (Windows; U; Win...\n",
       "153113    User-Agent:       Mozilla/5.0 (Windows NT 5.1;...\n",
       "28853     User-Agent:       Mozilla/5.0 (Windows; U; Win...\n",
       "                                ...                        \n",
       "145957    User-Agent:       Mozilla/5.0 (Windows; U; Win...\n",
       "101792    OS Name\\tMicrosoft Windows 7 Professional 64 B...\n",
       "176741    User-Agent:       Mozilla/5.0 (Windows; U; Win...\n",
       "259250    in toolbar.xml's itemChanged() [itemRemoved(),...\n",
       "44119     See URL.  This assertion gets triggered becaus...\n",
       "3309      (function () {\\n    const c = 0;\\n    with ({}...\n",
       "76254     Tested using the M15 Alpha build, ID 200004192...\n",
       "69193     Now we need to do a survey of how closures are...\n",
       "231282    User-Agent:       Mozilla/5.0 (Windows; U; Win...\n",
       "21695     STR:\\n1. visit http://blog.ianbicking.org/2012...\n",
       "150889    Variations on bug 429865's crashtest still cau...\n",
       "86078     GCC is gcc version 4.5.2 (Ubuntu/Linaro 4.5.2-...\n",
       "51460     User-Agent:       Mozilla/5.0 (Windows; U; Win...\n",
       "215909    User Agent: Mozilla/5.0 (Windows NT 6.1; WOW64...\n",
       "151306    I have a few ideas to make debugging display l...\n",
       "80127     nsCompressedCharMap::SetChars accesses unalign...\n",
       "57443     FillPaint and StrokePaint for in=\"\" and in2=\"\"...\n",
       "186729    User-Agent:       Mozilla/4.0 (compatible; MSI...\n",
       "83826     User-Agent:       Mozilla/5.0 (Windows; U; Win...\n",
       "241154    This is a commercial build on linux from 9/18 ...\n",
       "96147     User-Agent:       Mozilla/5.0 (Windows; U; Win...\n",
       "279025                                                     \n",
       "110274    User Agent: Mozilla/5.0 (Windows NT 6.1; WOW64...\n",
       "51490     User-Agent:       Mozilla/5.0 (X11; U; Linux i...\n",
       "18410     found using 2004113002-0.9 on Mac OS X 10.3.6....\n",
       "136052    User-Agent:       Mozilla/5.0 (X11; U; Linux i...\n",
       "134819    http://tinderbox.mozilla.org/showlog.cgi?log=S...\n",
       "44636     ###!!! ASSERTION: Invalid offset: 'aOffset <= ...\n",
       "139607    It started spiking in 20.0a1/20121206 along wi...\n",
       "7431      Hi, whenever i'm watching videos in youtube we...\n",
       "Name: desc_init, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_third['desc_init']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(df_third['desc_init'], df_third['severity_final'], test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(input='content', lowercase=True, tokenizer=None, \n",
    "                        stop_words='english', use_idf=True, \n",
    "                        token_pattern='[a-zA-Z]+',) #default token_pattern='(?u)\\b\\w\\w+\\b'\n",
    "tfidf = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (69963, 141415)\n",
      "test shape: (23321, 141415)\n"
     ]
    }
   ],
   "source": [
    "print 'train shape: {}'.format(tfidf.shape)\n",
    "tfidf_test = vectorizer.transform(X_test)\n",
    "print 'test shape: {}'.format(tfidf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101678    User-Agent:       Mozilla/5.0 (Macintosh; U; P...\n",
       "8125      We need to be able to configure at runtime whi...\n",
       "Name: desc_init, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'aa',\n",
       " u'aaa',\n",
       " u'aaaa',\n",
       " u'aaaaa',\n",
       " u'aaaaaa',\n",
       " u'aaaaaaa',\n",
       " u'aaaaaaaa',\n",
       " u'aaaaaaaaa',\n",
       " u'aaaaaaaaaa',\n",
       " u'aaaaaaaaaaa']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensionality Reduction - PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_model = PCA(n_components=10) #number of dimensions/topics required\n",
    "pca_model.fit(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_train = pca_model.transform(tfidf.toarray())\n",
    "\n",
    "sum(pca_model.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_test = pca_model.transform(tfidf_test.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_model.fit(tfidf,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = nb_model.predict(tfidf_test)\n",
    "\n",
    "print 'accuracy: {}'.format(sklearn.metrics.accuracy_score(y_test, y_pred))\n",
    "print 'precision: {}'.format(sklearn.metrics.precision_score(y_test, y_pred))\n",
    "print 'recall: {}'.format(sklearn.metrics.recall_score(y_test, y_pred))\n",
    "print ''\n",
    "print 'confusion matrix: \\n {}'.format(sklearn.metrics.confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
